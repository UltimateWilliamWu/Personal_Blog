{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db48d913-1b40-46f7-8a8c-51efedb569e8",
   "metadata": {},
   "source": [
    "**ZID**:z5518601 \n",
    "**Name**:Tianxiong Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219aac4-221b-4fb9-ac26-eb4ad03f3fa3",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Data Preparation](#1.1-Data-Preparation)\n",
    "3. [Task A – Classification: Hot Event Detection](#Task-A:Classification(Hot-event-detection))\n",
    "    - [A.1 Define Hot Label]\n",
    "    - [A.2 Feature Engineering]\n",
    "    - [A.3 Train / Val / Test Split]\n",
    "    - [A.4 Neural Network Classifier]\n",
    "    - [A.5 Evaluation & Confusion Matrix]\n",
    "4. [Task B – Regression: Temperature Prediction](#Task-B:-Regression-(Temperature-prediction))\n",
    "    - [B.1 Random Split – Model & Evaluation](#2.1-Model-development-(Random-Split-Regression))\n",
    "    - [B.2 Year-wise Split – Model & Evaluation](#2.3-Model-development-(year-wise-split-&-target-normalisation))\n",
    "5. [Final Evaluation Cell (Hidden Test Set)](#Final-Evaluation-Cell-(Hidden-Test-Set))\n",
    "6. [Model & Scaler Export Summary](#Model-&-Scaler-Export-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084738a-6c5e-4246-a048-2705fa54234b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook addresses two supervised learning tasks using neural networks:\n",
    "- A binary classification task to detect **hot events** in the Amazon.\n",
    "- A regression task to predict **monthly temperature values**.\n",
    "\n",
    "The model inputs include oceanic climate mode indices (ENSO, NAO, TSA, TNA) and cyclically encoded `month`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb14c7-a757-4a2a-ab58-6ceef593639e",
   "metadata": {},
   "source": [
    "## Task A: Classification (Hot event detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a14f73-b5ca-4b7c-93cb-8b02736d95f1",
   "metadata": {},
   "source": [
    "## 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46064494-562d-4088-bbba-27f8d615bf78",
   "metadata": {},
   "source": [
    "### A.1 Define Hot Label\n",
    "- Binary variable Hot is defined as:\n",
    "  - 1 if temperature > threshold of that month\n",
    "  - 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e0738-7298-4c0e-8e29-f5278ad18d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab90117-0f55-4a9c-9baa-6e3e3e135908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data, generate Hot labels, and visualise hot months per year\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1.1: Load temperature and climate mode data\n",
    "df = pd.read_csv('Amazon_temperature_student.csv')\n",
    "\n",
    "# Step 1.2: Load threshold values per month (no year needed)\n",
    "threshold_df = pd.read_csv('thresholds.csv')  # contains columns: Month, Threshold\n",
    "\n",
    "# Step 1.3: Generate Year and Month columns based on index\n",
    "start_year = 1982\n",
    "n_months = df.shape[0]\n",
    "df['Year'] = start_year + (np.arange(n_months) // 12)\n",
    "df['Month'] = (np.arange(n_months) % 12) + 1\n",
    "\n",
    "# Step 1.4: Map monthly threshold to each row\n",
    "month_to_thresh = dict(zip(threshold_df['month'], threshold_df['threshold']))\n",
    "df['threshold'] = df['month'].map(month_to_thresh)\n",
    "\n",
    "# Step 1.5: Generate binary Hot label\n",
    "df['Hot'] = (df['temperature'] > df['threshold']).astype(int)\n",
    "\n",
    "# Step 1.6: Visualise number of hot months per year\n",
    "hot_counts = df[df['Hot'] == 1].groupby('Year').size()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "hot_counts.plot(kind='bar', color='darkorange')\n",
    "plt.title('Number of Hot Months per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Hot Months')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97e461-283b-4ecb-ab50-529831c8adf0",
   "metadata": {},
   "source": [
    "## 1.2 Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38daeec3-c03d-4aa6-b80a-4c2b2732755c",
   "metadata": {},
   "source": [
    "### A.2 Feature Engineering\n",
    "\n",
    "- Features used: ENSO, NAO, TSA, TNA, Month (cyclically encoded using sin/cos)\n",
    "- `Year` is **not used** as a feature (per assignment constraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2befbde-346f-4d34-9e41-175a7bc02170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature preparation and model training for classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Step 2.1: Cyclic encode month\n",
    "df['Month_sin'] = np.sin(2 * np.pi * (df['Month'] - 1) / 12)\n",
    "df['Month_cos'] = np.cos(2 * np.pi * (df['Month'] - 1) / 12)\n",
    "\n",
    "# Step 2.2: Select features and target\n",
    "features = ['ENSO', 'TSA', 'TNA', 'NAO', 'Month_sin', 'Month_cos']\n",
    "X = df[features].values\n",
    "y = df['Hot'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8fb5f-87b8-4a36-b305-17be114171ee",
   "metadata": {},
   "source": [
    "### A.3 Train / Val / Test Split\n",
    "\n",
    "- Random split into 60% train, 20% validation, 20% test.\n",
    "- Features standardised using `StandardScaler` (fit on train only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597597b-b7d7-4492-b928-35e4c303008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3: Split into train/val/test (60/20/20)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Step 2.4: Standardise features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, 'classifier_feature_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a825ff-e75d-4ee2-8b9b-aac40bd53d37",
   "metadata": {},
   "source": [
    "### A.4 Neural Network Classifier\n",
    "\n",
    "- Architecture: `Input → Dense(16) → Dense(8) → Dense(1, sigmoid)`\n",
    "- Loss: `binary_crossentropy`, Optimiser: `Adam`\n",
    "- EarlyStopping enabled.\n",
    "- Accuracy vs Epoch curve plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1b833-b01a-4d12-8a47-4d164da3abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.5: Define neural network architecture\n",
    "# 构建简单的神经网络，确保参数量 < 样本数 / 10\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # 二分类任务\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 2.6: Train the model with early stopping\n",
    "# 启用 EarlyStopping，防止过拟合\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_val_scaled, y_val),\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)\n",
    "\n",
    "# Step 2.7: Plot accuracy vs epoch\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classification Accuracy vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.save('hot_event_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636257d-976c-4c43-b073-35702772ae56",
   "metadata": {},
   "source": [
    "## 1.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f62fab-9fe4-465b-a2d9-bc2062b7afa9",
   "metadata": {},
   "source": [
    "### A.5 Evaluation & Confusion Matrix\n",
    "\n",
    "- Model evaluated on test set:\n",
    "  - Confusion matrix plotted (positive class = `1`)\n",
    "  - Balanced Accuracy, Sensitivity (TPR), and Specificity (TNR) calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bad5b2-b877-4dde-9f45-dc8da06bb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score\n",
    "\n",
    "# Step 3.1: Predict on the test set\n",
    "y_pred_proba = model.predict(X_test_scaled).ravel()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # 二分类概率转为标签\n",
    "\n",
    "# Step 3.2: Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Hot (0)', 'Hot (1)'])\n",
    "disp.plot(cmap='Oranges')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3.3: Evaluation metrics\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)  # TPR\n",
    "specificity = recall_score(y_test, y_pred, pos_label=0)  # TNR\n",
    "\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "print(f\"True Positive Rate (Sensitivity): {sensitivity:.4f}\")\n",
    "print(f\"True Negative Rate (Specificity): {specificity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb9a8c-a4c3-4820-bbf0-ceb89ab95f71",
   "metadata": {},
   "source": [
    "## Task B: Regression (Temperature prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb13193-9c44-4630-b19c-7c4228efb433",
   "metadata": {},
   "source": [
    "## B.1 Random Split – Model & Evaluation\n",
    "\n",
    "- Input features same as classifier.\n",
    "- Output: temperature (continuous)\n",
    "- Target values **not scaled** (per requirement).\n",
    "- Train/val/test = 60/20/20 random split.\n",
    "- Network structure: `Dense(32) → Dense(16) → Dense(1)`\n",
    "- Loss: MSE, Metrics: MAE\n",
    "- MSE Loss vs Epoch curve plotted\n",
    "- Evaluated on test set using:\n",
    "  - Pearson Correlation Coefficient (r)\n",
    "  - Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317186ef-f21b-4b0e-a62a-e9eed1619c07",
   "metadata": {},
   "source": [
    "### 2.1 Model development (Random Split Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a6c26-b9c7-4a78-885e-c550602d576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step B1: Prepare data for regression task\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Step B1.1: Define features and target (Temperature)\n",
    "X = df[features].values  # features: ENSO, TSA, TNA, NAO, Month_sin, Month_cos\n",
    "y = df['temperature'].values\n",
    "\n",
    "# Step B1.2: Split randomly into train / val / test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step B1.3: Standardise features (do not touch y!)\n",
    "reg_scaler = StandardScaler()\n",
    "X_train_scaled = reg_scaler.fit_transform(X_train)\n",
    "X_val_scaled = reg_scaler.transform(X_val)\n",
    "X_test_scaled = reg_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce54d01-254d-4531-b23f-8f3999f0a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step B2: Build and train a regression neural network\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# 构建模型结构（参数数量 < 数据数 / 10）\n",
    "reg_model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)  # 回归输出\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "reg_model.compile(optimizer='adam',\n",
    "                  loss=MeanSquaredError(),\n",
    "                  metrics=['mae'])  # 使用 MAE 作为评估指标\n",
    "\n",
    "# 训练模型\n",
    "reg_history = reg_model.fit(X_train_scaled, y_train,\n",
    "                            validation_data=(X_val_scaled, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=32,\n",
    "                            callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "                            verbose=1)\n",
    "\n",
    "# 绘制 loss vs epoch 图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reg_history.history['loss'], label='Train Loss')\n",
    "plt.plot(reg_history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Regression Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045cd0cb-8ac2-4331-a439-3dd2a7cad97e",
   "metadata": {},
   "source": [
    "### 2.2 Model evaluation (Random Split Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c270a3-8240-42c0-b319-ed0d451fef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step B3: Evaluate regression model on test set\n",
    "y_pred = reg_model.predict(X_test_scaled).ravel()\n",
    "\n",
    "r, _ = pearsonr(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Pearson Correlation (r): {r:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d697598-70aa-491a-8726-fc7203fcc9dc",
   "metadata": {},
   "source": [
    "## B.2 Year-wise Split – Model & Evaluation\n",
    "- Years were randomly shuffled and grouped into:\n",
    "  - 60% training years, 20% validation years, 20% test years\n",
    "- Input features scaled using `StandardScaler`\n",
    "- Target values (`temperature`) scaled using `MinMaxScaler` (fit on training target only)\n",
    "- Same model structure reused\n",
    "- Model trained on scaled targets\n",
    "- Evaluation:\n",
    "  - Predictions inverse-transformed\n",
    "  - Pearson r and MAE reported\n",
    "  - True vs Predicted scatter plot plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49549bc4-7456-4969-b0c6-c8428882a181",
   "metadata": {},
   "source": [
    "### 2.3 Model development (year-wise split & target normalisation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65559a2-4929-4423-b53f-4ef891a60df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step B4.1: Split year-wise — group by year and assign to sets\n",
    "# Step (p): 年度划分 train/val/test（使用年份分组）\n",
    "years = df['Year'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(years)\n",
    "\n",
    "n_total = len(years)\n",
    "n_train = int(n_total * 0.6)\n",
    "n_val = int(n_total * 0.2)\n",
    "train_years = years[:n_train]\n",
    "val_years = years[n_train:n_train + n_val]\n",
    "test_years = years[n_train + n_val:]\n",
    "\n",
    "# 依据年份划分数据\n",
    "df_train = df[df['Year'].isin(train_years)]\n",
    "df_val = df[df['Year'].isin(val_years)]\n",
    "df_test = df[df['Year'].isin(test_years)]\n",
    "\n",
    "# 选特征和目标\n",
    "features = ['ENSO', 'TSA', 'TNA', 'NAO', 'Month_sin', 'Month_cos']\n",
    "X_train_y = df_train[features].values\n",
    "X_val_y = df_val[features].values\n",
    "X_test_y = df_test[features].values\n",
    "\n",
    "y_train_y = df_train['temperature'].values.reshape(-1, 1)\n",
    "y_val_y = df_val['temperature'].values.reshape(-1, 1)\n",
    "y_test_y = df_test['temperature'].values.reshape(-1, 1)\n",
    "\n",
    "# Step (q): 特征标准化（和随机划分一致）\n",
    "year_feature_scaler = StandardScaler()\n",
    "X_train_y_scaled = year_feature_scaler.fit_transform(X_train_y)\n",
    "X_val_y_scaled = year_feature_scaler.transform(X_val_y)\n",
    "X_test_y_scaled = year_feature_scaler.transform(X_test_y)\n",
    "\n",
    "# 目标值使用 MinMaxScaler 单独归一化\n",
    "target_scaler = MinMaxScaler()\n",
    "y_train_y_scaled = target_scaler.fit_transform(y_train_y)\n",
    "y_val_y_scaled = target_scaler.transform(y_val_y)\n",
    "y_test_y_scaled = target_scaler.transform(y_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375d20f-cd79-419b-8628-bb24ed1a78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step (r): 模型结构不变，重新训练\n",
    "year_model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_y_scaled.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "year_model.compile(optimizer='adam',\n",
    "                   loss='mse',\n",
    "                   metrics=['mae'])\n",
    "\n",
    "# Step (r): 训练\n",
    "year_history = year_model.fit(X_train_y_scaled, y_train_y_scaled,\n",
    "                              validation_data=(X_val_y_scaled, y_val_y_scaled),\n",
    "                              epochs=100,\n",
    "                              batch_size=32,\n",
    "                              callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "                              verbose=1)\n",
    "\n",
    "# Step (s): 绘制 loss 曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(year_history.history['loss'], label='Train Loss')\n",
    "plt.plot(year_history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Year-wise Regression Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1418bc-4e8b-4368-970a-2875af7792fc",
   "metadata": {},
   "source": [
    "### 2.4 Model evaluation (Year-wise Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a6699-bf92-4bea-834d-adeedd8e2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step (t): Year-wise \n",
    "y_pred_scaled = year_model.predict(X_test_y_scaled)\n",
    "y_pred = target_scaler.inverse_transform(y_pred_scaled).ravel()\n",
    "y_true = y_test_y.ravel()\n",
    "\n",
    "# Pearson \n",
    "r_year, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "# MAE\n",
    "mae_year = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"[Year-wise] Pearson Correlation (r): {r_year:.4f}\")\n",
    "print(f\"[Year-wise] Mean Absolute Error (MAE): {mae_year:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e79b8-3dbc-47ec-a90f-6f2069e1d97a",
   "metadata": {},
   "source": [
    "## Final Evaluation Cell (Hidden Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5ea4-de92-4358-bf96-3a9b4a53dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Save all models and scalers\n",
    "import joblib\n",
    "\n",
    "# Save classifier\n",
    "model.save('hot_event_classifier.h5')\n",
    "joblib.dump(scaler, 'classifier_feature_scaler.pkl')\n",
    "\n",
    "# Save regressor (random split)\n",
    "reg_model.save('regressor_random_split.h5')\n",
    "joblib.dump(reg_scaler, 'regressor_feature_scaler.pkl')\n",
    "\n",
    "# Save regressor (year-wise split)\n",
    "year_model.save('regressor_yearwise_split.h5')\n",
    "joblib.dump(year_feature_scaler, 'regressor_yearwise_feature_scaler.pkl')\n",
    "joblib.dump(target_scaler, 'regressor_yearwise_target_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab19f8-4dd1-4f42-b1bc-522dcf72e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Final evaluation cell for hidden test data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load hidden test set (assumed preloaded as hidden_df)\n",
    "hidden_df = pd.read_csv('hidden_test.csv')  # provided by course staff\n",
    "\n",
    "# Step 2.1: Cyclic encoding of Month\n",
    "hidden_df['Month_sin'] = np.sin(2 * np.pi * (hidden_df['Month'] - 1) / 12)\n",
    "hidden_df['Month_cos'] = np.cos(2 * np.pi * (hidden_df['Month'] - 1) / 12)\n",
    "features = ['ENSO', 'TSA', 'TNA', 'NAO', 'Month_sin', 'Month_cos']\n",
    "\n",
    "# === Classifier Evaluation ===\n",
    "X_cls = joblib.load('classifier_feature_scaler.pkl').transform(hidden_df[features])\n",
    "cls_model = load_model('hot_event_classifier.h5')\n",
    "y_true_cls = hidden_df['Hot'].values\n",
    "y_pred_cls = (cls_model.predict(X_cls).ravel() > 0.5).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_cls, y_pred_cls)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Not Hot', 'Hot']).plot(cmap='Oranges')\n",
    "plt.title(\"Confusion Matrix - Classifier on Hidden Test\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(\"[Classifier]\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_true_cls, y_pred_cls):.4f}\")\n",
    "print(f\"Sensitivity (TPR): {recall_score(y_true_cls, y_pred_cls):.4f}\")\n",
    "print(f\"Specificity (TNR): {recall_score(y_true_cls, y_pred_cls, pos_label=0):.4f}\")\n",
    "\n",
    "# === Random-split Regressor Evaluation ===\n",
    "X_reg = joblib.load('regressor_feature_scaler.pkl').transform(hidden_df[features])\n",
    "y_true_reg = hidden_df['Temperature'].values\n",
    "reg_model = load_model('regressor_random_split.h5')\n",
    "y_pred_reg = reg_model.predict(X_reg).ravel()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_true_reg, y_pred_reg, alpha=0.5)\n",
    "plt.title(\"Random Split: True vs Predicted Temperature\")\n",
    "plt.xlabel(\"True Temp\")\n",
    "plt.ylabel(\"Predicted Temp\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[Regressor - Random Split]\")\n",
    "r1, _ = pearsonr(y_true_reg, y_pred_reg)\n",
    "mae1 = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "print(f\"Pearson r: {r1:.4f}\")\n",
    "print(f\"MAE: {mae1:.4f}\")\n",
    "\n",
    "# === Year-wise Regressor Evaluation ===\n",
    "X_yw = joblib.load('regressor_yearwise_feature_scaler.pkl').transform(hidden_df[features])\n",
    "y_yw_true = hidden_df['Temperature'].values.reshape(-1, 1)\n",
    "y_model = load_model('regressor_yearwise_split.h5')\n",
    "y_scaled_pred = y_model.predict(X_yw)\n",
    "y_pred_yw = joblib.load('regressor_yearwise_target_scaler.pkl').inverse_transform(y_scaled_pred).ravel()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_yw_true.ravel(), y_pred_yw, alpha=0.5)\n",
    "plt.title(\"Year-wise Split: True vs Predicted Temperature\")\n",
    "plt.xlabel(\"True Temp\")\n",
    "plt.ylabel(\"Predicted Temp\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[Regressor - Year-wise Split]\")\n",
    "r2, _ = pearsonr(y_yw_true.ravel(), y_pred_yw)\n",
    "mae2 = mean_absolute_error(y_yw_true.ravel(), y_pred_yw)\n",
    "print(f\"Pearson r: {r2:.4f}\")\n",
    "print(f\"MAE: {mae2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c1185-f1f9-4643-94f1-e2389ee47b71",
   "metadata": {},
   "source": [
    "## Model & Scaler Export Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825a7cd-8028-43db-9e00-4a050ba2abb9",
   "metadata": {},
   "source": [
    "| Type | File Name |\n",
    "|------|-----------|\n",
    "| Classifier Model | `hot_event_classifier.h5` |\n",
    "| Classifier Scaler | `classifier_feature_scaler.pkl` |\n",
    "| Regressor (Random) | `regressor_random_split.h5` |\n",
    "| Regressor Scaler | `regressor_feature_scaler.pkl` |\n",
    "| Regressor (Year-wise) | `regressor_yearwise_split.h5` |\n",
    "| Feature Scaler (Year-wise) | `regressor_yearwise_feature_scaler.pkl` |\n",
    "| Target Scaler (Year-wise) | `regressor_yearwise_target_scaler.pkl` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
